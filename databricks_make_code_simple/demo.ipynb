{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e28d7364-cb6e-4dd3-8044-6f785da41e46",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#setting up "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "156d3325-66d4-4198-8e10-1821fbae4849",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "account_key = \"your_access_key\"\n",
    "spark.conf.set(\"fs.azure.account.key.kaninipro.dfs.core.windows.net\",account_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f3165b58-d30b-419a-81e4-cd07bc0a97e9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#Read file with metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f6cab207-6cb3-4dd3-b4b9-52621469704d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "city_weather = spark.read.format(\"parquet\")\\\n",
    "                .load(\"abfss://data@kaninipro.dfs.core.windows.net/city_weather_parquet\")\\\n",
    "                .selectExpr(\"*\",\n",
    "                            \"_metadata.file_path as file_path\",\n",
    "                            \"_metadata.file_name as file_name\",\n",
    "                            \"_metadata.file_modification_time as file_modification_time\",\n",
    "                            \"_metadata.file_size as file_size\",\n",
    "                            \"_metadata.file_block_length as file_block_length\",\n",
    "                            \"_metadata.file_block_start as file_block_start\"\n",
    "                            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2a4f3b3e-8b3a-4d0d-81fd-b7dca7011d71",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\",\"city\"],\"right\":[]},\"columnSizing\":{\"file_name1\":291,\"file_path\":276},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1763231197977}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(city_weather)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ce5b5aaf-b22c-44fa-8432-df2ce1518d3c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#eqNullSafe for safe equality checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7ceb7674-f6cc-4126-bfc0-89a6970fad2d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import expr, col\n",
    "\n",
    "df = spark.createDataFrame([\n",
    "    (1, 1),\n",
    "    (None, None),\n",
    "    (None, 5),\n",
    "    (10, None)\n",
    "], [\"col1\", \"col2\"])\n",
    "\n",
    "col_added_df = df.withColumn(\"is_equal\", col(\"col1\").eqNullSafe(col(\"col2\")))\n",
    "\n",
    "display(col_added_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b0cfef4d-3c2c-4bd2-8f99-72d3db13b0f3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df1 = spark.createDataFrame([\n",
    "    (1, \"A\"),\n",
    "    (None, \"B\"),\n",
    "    (3, \"C\")\n",
    "], [\"id\", \"value1\"])\n",
    "\n",
    "df2 = spark.createDataFrame([\n",
    "    (1, \"X\"),\n",
    "    (None, \"Y\"),\n",
    "    (4, \"Z\")\n",
    "], [\"id\", \"value2\"])\n",
    "\n",
    "result = df1.join(\n",
    "    df2,\n",
    "    df1[\"id\"].eqNullSafe(df2[\"id\"]),\n",
    "    \"inner\"\n",
    ")\n",
    "\n",
    "display(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "827c4bac-0c14-47d1-9f61-cce42cf76b9b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#sort array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3b7a40f3-19b8-4706-9602-377ff96086b2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, ArrayType\n",
    "from pyspark.sql.functions import sort_array, col\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"id\", IntegerType(), True),\n",
    "    StructField(\n",
    "        \"array_field\",\n",
    "        ArrayType(\n",
    "            StructType([\n",
    "                StructField(\"field1\", IntegerType(), True),\n",
    "                StructField(\"field2\", StringType(), True)\n",
    "            ])\n",
    "        ),\n",
    "        True\n",
    "    )\n",
    "])\n",
    "\n",
    "data = [\n",
    "    (1, [\n",
    "        {\"field1\": 10, \"field2\": \"def\"},\n",
    "        {\"field1\": 70, \"field2\": \"ghi\"},\n",
    "        {\"field1\": 70, \"field2\": \"abc\"}\n",
    "    ]),\n",
    "    (2, [\n",
    "        {\"field1\": 10, \"field2\": \"ijk\"},\n",
    "        {\"field1\": 20, \"field2\": \"sdg\"},\n",
    "    ]),\n",
    "    (3, [\n",
    "        {\"field1\": 100, \"field2\": \"abc\"},\n",
    "        {\"field1\": 5, \"field2\": \"ood\"},\n",
    "        {\"field1\": 5, \"field2\": \"afe\"}\n",
    "    ])\n",
    "]\n",
    "\n",
    "df = spark.createDataFrame(data, schema=schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d25502b1-e26b-4fd1-a0e4-42699cca3e88",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{\"array_field\":485},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1763268319094}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9466a8ef-174f-41c5-9956-685ea8eff6fa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(df.select(\"id\",sort_array(col(\"array_field\"))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2b560761-11dd-45b9-9811-298570acc3f3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#Apply inline transform on arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "71ce9633-d830-49b7-80ac-36fe5a074d2a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "04408969-55f1-40d5-b375-7a5213076d64",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "87bbf2ce-cc5b-46fc-bed1-84bd7b555473",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2913a06e-4470-4a48-91bb-5cedbb0c4f48",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d8b03bca-32a3-4136-9eb8-70c6ba16bcc9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4cf0f622-a82a-4420-a951-bb0e6cbf2b6b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "db78c454-7b44-407e-9075-5f4aa95ba0d8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f18652a2-a647-4ce7-b1a8-129a5d75220f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c96829fc-1f94-44f6-9db5-e2d4f541103f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#PySpark DataFrame equality functions for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1fb937cd-6a57-457b-a004-dec7f424ab44",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.testing import assertSchemaEqual\n",
    "\n",
    "schema_actual = \"name STRING, amount DOUBLE\"\n",
    "\n",
    "data_expected = [[\"Bob\", 1000], [\"Bob\", 2000], [\"Carol\", 700], [\"Carol\", 3500]]\n",
    "data_actual = [[\"Bob\", 1000.0], [\"Bob\", 2000.0], [\"Carol\", 700.0], [\"Carol\", 3500.0]]\n",
    "\n",
    "df_expected = spark.createDataFrame(data = data_expected)\n",
    "df_actual = spark.createDataFrame(data = data_actual, schema = schema_actual)\n",
    "\n",
    "\n",
    "\n",
    "assertSchemaEqual(df_actual.schema, df_expected.schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7b580b73-6f35-4be7-b0b6-dfef1546a567",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_expected = spark.createDataFrame(data=[(\"Alfred\", 1500), (\"Alfred\", 2500), (\"Anna\", \n",
    "500), (\"Anna\", 3000)], schema=[\"name\", \"amount\"])\n",
    "\n",
    "df_actual = spark.createDataFrame(data=[(\"Alfred\", 1200), (\"Alfred\", 2500), (\"Anna\", 500), \n",
    "(\"Anna\", 3000)], schema=[\"name\", \"amount\"])\n",
    "\n",
    "from pyspark.testing import assertDataFrameEqual\n",
    "\n",
    "assertDataFrameEqual(df_actual, df_expected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "676d8636-9900-461a-aa2a-e6a78c38647b",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{\"Actual\":232,\"Expected\":246},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1763267506934}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_expected = spark.createDataFrame(data=[\n",
    "                                            (\"Alfred\", 1500), \n",
    "                                            (\"Alfred\", 2500), \n",
    "                                            (\"Anna\", 500), \n",
    "                                            (\"Anna\", 3000)], \n",
    "                                    schema=[\"name\", \"amount\"]\n",
    "                                    )\n",
    "\n",
    "df_actual = spark.createDataFrame(data=[\n",
    "                                 (\"Alfred\", 1200), \n",
    "                                 (\"Alfred\", 300), \n",
    "                                 (\"Anna\", 500), \n",
    "                                 (\"Anna\", 3000)], \n",
    "                            schema=[\"name\", \"amount\"]\n",
    "                            )\n",
    "\n",
    "\n",
    "from pyspark.testing import assertDataFrameEqual\n",
    "from pyspark.errors import PySparkAssertionError\n",
    "\n",
    "try:\n",
    "    assertDataFrameEqual(df_actual, df_expected, includeDiffRows=True)\n",
    "except PySparkAssertionError as e:\n",
    "    # `e.data` here looks like:\n",
    "    # [(Row(name='Alfred', amount=1200), Row(name='Alfred', amount=1500))]\n",
    "    errored_recrods = spark.createDataFrame(e.data, schema=[\"Actual\", \"Expected\"])\n",
    "\n",
    "display(errored_recrods)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3262ec4a-daeb-44f1-9b49-f412d52f3bbd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#prefer unionByName over union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "560e7066-846f-4989-b4f9-bc15f0fd0942",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df1 = spark.createDataFrame(\n",
    "    [(1, \"Arul\", 30)],\n",
    "    [\"id\", \"name\", \"age\"]\n",
    ")\n",
    "\n",
    "df2 = spark.createDataFrame(\n",
    "    [(2, 28, \"Meena\")],   # Notice: order is different → (id, age, name)\n",
    "    [\"id\", \"age\", \"name\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "763b7f0b-468d-464b-96ea-9212de246397",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(df1.union(df2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6247ed4c-8703-452e-a007-e903b0689f2b",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1763269923105}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(df1.unionByName(df2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "30fe2479-67b7-4f78-a3f0-dbe1d7affd02",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##handling missing columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a022abd2-4e59-4ef4-b71b-28c841adb0de",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df1 = spark.createDataFrame(\n",
    "    [(1, 30)],\n",
    "    [\"id\", \"age\"]\n",
    ")\n",
    "\n",
    "df2 = spark.createDataFrame(\n",
    "    [(2, 28, \"Meena\")],   # Notice: order is different → (id, age, name)\n",
    "    [\"id\", \"age\", \"name\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e3d68d85-950b-4372-9c1a-6befdc7f94b8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(df1.unionByName(df2, allowMissingColumns=True))"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "demo",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
